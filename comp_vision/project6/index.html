<html>
<head>
<title>CV Project 6</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
<script type="text/javascript" src="http://latex.codeco/gs.com/latexit.js"></script>

<link rel="stylesheet" href="../highlighting/styles/default.css">
<script src="../highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: -apple-system, ".SFNSText-Regular", "San Francisco", "Roboto", "Segoe UI", "Helvetica Neue", "Lucida Grande", sans-serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	//text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 960px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

img.pad {
	padding-left: 10px;
	padding-right: 10px;
}

a.secret {
	text-decoration: none;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

td img {
  vertical-align: middle;
}

table, th, td {
   border: 1px solid #CCC;
   border-collapse: collapse;
	border-spacing: 0;
}

td {
    text-align: center;
    vertical-align: middle;
    background: #FAFAFA; /* Lighter grey background */
}

th {
	padding: 4px;
	background: #F3F3F3; /* Light grey background */
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Daniel Puleri <span style="color: #DE3737">(<a class="secret" href="http://dpuleri.com">dpuleri3</a>)</span></h1>
</div>
</div>
<div class="container">

<h2>CS 4495 / 6476 Project 6: Deep Learning</h2>

<p>In this project, we continued with the same type of computer vision problem as in <a href="http://www.cc.gatech.edu/~hays/compvision/proj4">project 4</a>, scene recognition. Except this time, we are now using deep learning to categorize the images! We used a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> from the <a href="http://www.vlfeat.org/matconvnet/">MatConvNet</a> library to categorize these different images into 15 categories. Now, since we only had 1,500 images to train on and no pre-trained network (I only did part 1), it was unlikely that performance would surpass that which we got in project 4. I personally got an accuracy of 62.4% on my best try in project 4. Please jump to the <a href="#summary">summary</a> if you want to see all of my results in one place for this project.</p>

<h3 id="base-net">Base network</h3>
<p>With just a base network, I was able to get 28.3% accuracy. This is exactly what was to be expected and it will be used as a basis for comparison for the rest of these results.</p>

<center>
<a href="plt_default_30_epochs.png"><img src="plt_default_30_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the error over time for the default network.</p>
</center>
<br />

<center>
<a href="filter_default_30_epochs.png"><img src="filter_default_30_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the default network.</p>
</center>

<p>The filter does not look like it really means anything for the default network and that makes sense since it really is not recognizing much. Even though its 28% accuracy is way better than random accuracy.</p>
<br />

<h3 id="jitter-net">Network with jittering</h3>

<p>For this run, we added jittering. To add this noise to the network, effectively making our training set larger, I flipped half of the images from left to right as they were called for training. I didn't want this to happen deterministically, so I made the images that were to be mirrored be random and non-repeating.</p>

<pre><code>
imgs_to_flip = randperm(length(batch),length(batch)/2); % pick random images to flip
for i = imgs_to_flip
    cur_im = im(:,:,:,i);
    cur_im = fliplr(cur_im);
    im(:,:,:,i) = cur_im;
end
</code></pre>

<p>This yielded an accuracy of 34.3% with 30 epochs and 37.7% with 100 epochs. The number of epochs is basically the number of rounds you let training and validation go. Since we have a small amount of training data, only 1,500 images, raising the number of epochs would have diminishing returns. In the figure below, one can even see that adding more epochs isn't going to do much for the <code>valtop1e</code> line (measure of the amount of error in the highest scoring guess). The energy for the <code>val</code> training line is also not decreasing.</p>

<center>
<a href="plt_jitter_100_epochs.png"><img src="plt_jitter_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the error over time for the network with jitter and 100 epochs. 30 epochs can be seen <a href="plt_jitter_30_epochs.png">here</a>.</p>
</center>
<br />

<center>
<a href="filter_jitter_100_epochs.png"><img src="filter_jitter_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the network with jitter and 100 epochs. It still doesn't look like much. 30 epochs can be seen <a href="filter_jitter_30_epochs.png">here</a>.</p>
</center>
<br />
<br />


<h3 id="zero-center-net">Network with jittering + zero-centering</h3>

<p>Next I added zero-centering which requires that the average of all of the images be subtracted from every pixel of each image.</p>

<p>This increased the accuracy to 50.8% with 30 epochs and to 53.3% with 100 epochs.</p>

<center>
<a href="plt_zerocenter_100_epochs.png"><img src="plt_zerocenter_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the error over time for the network with jitter and zero-centering. This is for 100 epochs. 30 epochs can be seen <a href="plt_zerocenter_30_epochs.png">here</a>.</p>
</center>
<br />

<center>
<a href="filter_zerocenter_100_epochs.png"><img src="filter_zerocenter_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the network with jitter and zero-centering. This is for 100 epochs. It finally looks like there are some authorization and vertical filters being learned! 30 epochs can be seen <a href="filter_zerocenter_30_epochs.png">here</a>.</p>
</center>
<br />
<br />

<h3 id="dropout-reg-net">Network with jittering + zero-centering + dropout regularization</h3>

<p>Next, we added <a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf">dropout regularization</a>. This is a method of fighting overfitting in the network as it randomly turns off neurons/perceptrons.</p>

<p>By adding dropout regularization, I was able to get the accuracy up to 53.1% with 30 epochs and <strong>58.4%</strong> with 100 epochs. This was my best result overall! Even better than the relatively deeper networks that I did later on and it only took 10 minutes to train.</p>

<center>
<a href="plt_dropout_100_epochs.png"><img src="plt_dropout_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the error over time for the network with jitter, zero-centering, and dropout regularization. This is for 100 epochs. 30 epochs can be seen <a href="plt_dropout_30_epochs.png">here</a>.</p>
</center>
<br />

<center>
<a href="filter_dropout_100_epochs.png"><img src="filter_dropout_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the network with jitter, zero-centering, and dropout regularization. This is for 100 epochs. These filters look very defined in the vertical and horizontal directions. The ones on the top left and in the second column even look quite complex. 30 epochs can be seen <a href="filter_dropout_30_epochs.png">here</a>.</p>
</center>
<br />
<br />

<h3 id="deep-net">Making this network deeper!</h3>

<p>I then made this network deeper by adding more layers. First, I went crazy and added 4 more layers to make a network that was 6 layers deep. This didn't turn out as well as I expected and I got results that were only 32.3% accuracy with 100 epochs. As can be seen in the chart below, it looks like the error was trending lower; however, it already took 43 minutes to train this network so I chalked it up to this extra deep network not working so well. As was already hinted in the problem statement, even with a deeper network it would be difficult to outperform the shallow one.</p>

<center>
<a href="plt_6deep_100_epochs.png"><img src="plt_6deep_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the 6 layers deep network. 30 epochs can be seen <a href="plt_6deep_30_epochs.png">here</a>.</p>
</center>
<br />

<center>
<a href="filter_6deep_100_epochs.png"><img src="filter_6deep_100_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the 6 layers deep network. The filter does not look like much. 30 epochs can be seen <a href="filter_6deep_30_epochs.png">here</a>.</p>
</center>
<br />

<p>After this, I had some more energy, so I tried to lower the amount of layers and with 3 layers I got better results. With 100 epochs I was able to achieve 52.7% accuracy and with 200 epochs I was able to get 54.3% accuracy in 30 minutes of training. This is still not as good as I was able to get with the <a href="#dropout-reg-net">shallow network</a>, but at least it came close this time. The architecture of this deep, but not <em>too</em> deep, network can be seen below.</p>

<pre><code>
     layer|    0|    1|    2|   3|    4|    5|    6|      7|   8|      9|
      type|input| conv|mpool|relu| conv|mpool| relu|dropout|conv|softmxl|
      name|  n/a|conv1|     |    |conv1|     |     |       | fc1|       |
----------|-----|-----|-----|----|-----|-----|-----|-------|----|-------|
   support|  n/a|    9|    3|   1|    8|    3|    1|      1|   9|      1|
  filt dim|  n/a|    1|  n/a| n/a|    1|  n/a|  n/a|    n/a|  10|    n/a|
 num filts|  n/a|   10|  n/a| n/a|   10|  n/a|  n/a|    n/a|  15|    n/a|
    stride|  n/a|    1|    2|   1|    1|    2|    1|      1|   1|      1|
       pad|  n/a|    0|    0|   0|    0|    0|    0|      0|   0|      0|
----------|-----|-----|-----|----|-----|-----|-----|-------|----|-------|
   rf size|  n/a|    9|   11|  11|   25|   29|   29|     29|  61|     61|
 rf offset|  n/a|    5|    6|   6|   13|   15|   15|     15|  31|     31|
 rf stride|  n/a|    1|    2|   2|    2|    4|    4|      4|   4|      4|
----------|-----|-----|-----|----|-----|-----|-----|-------|----|-------|
 data size|   64|   56|   27|  27|   20|    9|    9|      9|   1|      1|
data depth|    1|   10|   10|  10|   10|   10|   10|     10|  15|      1|
  data num|   50|   50|   50|  50|   50|   50|   50|     50|  50|      1|
----------|-----|-----|-----|----|-----|-----|-----|-------|----|-------|
  data mem|800KB|  6MB|  1MB| 1MB|781KB|158KB|158KB|  158KB| 3KB|     4B|
 param mem|  n/a|  3KB|   0B|  0B|  3KB|   0B|   0B|     0B|48KB|     0B|
</code></pre>

<center>
<a href="plt_3deep_200_epochs.png"><img src="plt_3deep_200_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the 3 layers deep network. 30 epochs can be seen <a href="plt_3deep_100_epochs.png">here</a>.</p>
</center>
<br />

<center>
<a href="filter_3deep_200_epochs.png"><img src="filter_3deep_200_epochs.png" /></a>
<p style="font-size: 14px">Visualization of the filter for the 3 layers deep network. The filter does not look like much. 100 epochs can be seen <a href="filter_3deep_100_epochs.png">here</a>.</p>
</center>
<br />

<h2 id="summary">In summary</h2>

<p>In summary, with the shallow network and all of the optimization tweaks, I was able to get an accuracy of 58.4%! I imagine with more training data and more time/compute power a deeper network could do much better. The results of all of my trials are summarized in the able below.</p>

<center>
<table>
	<tr>
		<th>Network Details</th>
		<th>Accuracy (%)</th>
		<th>Number of Epochs</th>
	</tr>
	<tr>
		<td>default code</td>
		<td>28.3</td>
		<td>30</td>
	</tr>
	<tr>
		<td>jittering</td>
		<td>34.4</td>
		<td>30</td>
	</tr>
	<tr>
		<td>jittering</td>
		<td>37.7</td>
		<td>100</td>
	</tr>
	<tr>
		<td>jittering and zero-centering</td>
		<td>50.8</td>
		<td>30</td>
	</tr>
	<tr>
		<td>jittering and zero-centering</td>
		<td>53.2</td>
		<td>100</td>
	</tr>
	<tr>
		<td>jittering and zero-centering and dropout</td>
		<td>53.1</td>
		<td>30</td>
	</tr>
	<tr>
		<td><strong>jittering and zero-centering</strong></td>
		<td><strong>58.5</strong></td>
		<td><strong>100</strong></td>
	</tr>
	<tr>
		<td>3 deep</td>
		<td>52.7</td>
		<td>100</td>
	</tr>
	<tr>
		<td>3 deep</td>
		<td>54.3</td>
		<td>200</td>
	</tr>
	<tr>
		<td>6 deep</td>
		<td>17.3</td>
		<td>30</td>
	</tr>
	<tr>
		<td>6 deep</td>
		<td>32.3</td>
		<td>100</td>
	</tr>
</table>
</center>

<br />
<br />

</div>
</body>
</html>